{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMb/murjGcwXExlqdeP5c1n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joyduttahere/AppAnalyzer2.0/blob/main/Share_AppAnalyzer2_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# App Analyzer 2.0: Setup & Launch Guide\n",
        "\n",
        "Welcome! This notebook will guide you through setting up and running the App Analyzer dashboard.\n",
        "\n",
        "---\n",
        "\n",
        "### **Step 1: Set the Correct Runtime (Crucial First Step!)**\n",
        "\n",
        "This application requires a GPU to run the sentiment analysis model efficiently.\n",
        "1. In the top menu, go to **Runtime â†’ Change runtime type**.\n",
        "2. In the popup window, select **T4 GPU** from the \"Hardware accelerator\" dropdown.\n",
        "3. Click **Save**.\n",
        "\n",
        "---\n",
        "\n",
        "### **Step 2: Get Your 3 Required API Keys & Permissions**\n",
        "\n",
        "Before running any code, you must get the following free credentials and save them somewhere safe:\n",
        "\n",
        "**1. Hugging Face Access & Token:**\n",
        "   * **a) Get Your Token:** Go to your [Hugging Face Tokens page](https://huggingface.co/settings/tokens). Create a new token with **\"read\"** permissions.\n",
        "   * *(Note: Access to the sentiment model is public, so no special permissions are needed beyond having an account and token.)*\n",
        "\n",
        "**2. Google Gemini API Key:**\n",
        "   * Go to [Google AI Studio](https://aistudio.google.com/) and click **\"Get API key\"** -> **\"Create API key\"**.\n",
        "\n",
        "**3. ngrok Authtoken:**\n",
        "   * Sign up or log in at the [ngrok Dashboard](https://dashboard.ngrok.com/signup). Your authtoken is on the [\"Your Authtoken\" page](https://dashboard.ngrok.com/get-started/your-authtoken).\n",
        "\n",
        "---\n",
        "\n",
        "### **Step 3: Add Your Secret Keys**\n",
        "\n",
        "The cell below will not run correctly until you add your secret keys.\n",
        "\n",
        "1.  Click the **key icon (ðŸ”‘)** in the left sidebar to open the Secrets Manager.\n",
        "2.  Click **\"Add a new secret\"** and create the following three secrets:\n",
        "    *   Name: `GEMINI_API_KEY` | Value: `(paste your Gemini key here)`\n",
        "    *   Name: `HF_TOKEN` | Value: `(paste your Hugging Face token here)`\n",
        "    *   Name: `NGROK_AUTHTOKEN` | Value: `(paste your ngrok authtoken here)`\n",
        "3.  Make sure the \"Notebook access\" toggle is **ON** for all three secrets.\n",
        "\n",
        "---\n",
        "\n",
        "### **Step 4: Run the Cells in Order**\n",
        "\n",
        "Now you are ready to run the code. Execute the following cells from top to bottom."
      ],
      "metadata": {
        "id": "im0JBlSp-6sd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Cell 1: Clone Repository & Install Dependencies\n",
        "import os\n",
        "\n",
        "# --- Clone the Repository ---\n",
        "if not os.path.exists('AppAnalyzer2.0'):\n",
        "    print(\"Cloning the AppAnalyzer2.0 repository...\")\n",
        "    !git clone https://github.com/joyduttahere/AppAnalyzer2.0.git\n",
        "%cd AppAnalyzer2.0\n",
        "\n",
        "print(\"\\n--- Installing all required packages ---\")\n",
        "\n",
        "# --- Upgrade pip and install all dependencies ---\n",
        "!pip install --upgrade pip -q\n",
        "!pip install -r requirements.txt -q\n",
        "!pip install google-generativeai pyngrok -q\n",
        "!pip install jedi==0.18.2 -q # To resolve potential Colab ipython conflicts\n",
        "\n",
        "print(\"\\nâœ… Environment setup complete.\")"
      ],
      "metadata": {
        "id": "X90_2eYI_AKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Set Environment Variables & Authenticate\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "print(\"Loading Colab secrets into environment variables...\")\n",
        "\n",
        "# --- Load secrets and set as environment variables for the app.py script ---\n",
        "try:\n",
        "    os.environ['NGROK_AUTHTOKEN'] = userdata.get('NGROK_AUTHTOKEN')\n",
        "    os.environ['HF_TOKEN'] = userdata.get('HF_TOKEN')\n",
        "    os.environ['GEMINI_API_KEY'] = userdata.get('GEMINI_API_KEY')\n",
        "    print(\"âœ… Secrets loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸ Warning: Could not load one or more secrets. Please ensure they are set correctly. Error: {e}\")\n",
        "\n",
        "# --- Authenticate with Hugging Face ---\n",
        "print(\"\\nLogging into Hugging Face Hub...\")\n",
        "# Use the environment variable for login\n",
        "!huggingface-cli login --token $HF_TOKEN\n",
        "print(\"\\nAuthentication step complete. Ready to launch.\")"
      ],
      "metadata": {
        "id": "WQ2WAXC8_Dcw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### **Step 5: Launch the Application**\n",
        "\n",
        "You're all set! Run the cell below to start the Flask web server. A public URL from `ngrok` will appear. Click on it to open the application in a new browser tab."
      ],
      "metadata": {
        "id": "P7TGhwpbdY-f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Run the Flask Application\n",
        "!python app.py"
      ],
      "metadata": {
        "id": "GQ0u6rw5_G0Y",
        "outputId": "f96266c0-ca4a-4849-e8e2-6944ac44e98c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting ngrok tunnel...\n",
            "================================================================================\n",
            "âœ… App is live at: NgrokTunnel: \"https://5161a6e100ce.ngrok-free.app\" -> \"http://localhost:5000\"\n",
            "================================================================================\n",
            " * Serving Flask app 'app'\n",
            " * Debug mode: off\n",
            "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "127.0.0.1 - - [16/Sep/2025 08:15:15] \"GET / HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [16/Sep/2025 08:15:17] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "Searching for: Google calendar in in\n",
            "127.0.0.1 - - [16/Sep/2025 08:15:27] \"POST /search-apps HTTP/1.1\" 200 -\n",
            "Scrape params: app_id=com.google.android.calendar, country=in, dr1=2025-09-08 - 2025-09-09, dr2=2025-09-01 - 2025-09-02\n",
            "127.0.0.1 - - [16/Sep/2025 08:15:42] \"POST /scrape-reviews HTTP/1.1\" 200 -\n",
            "Looking for cache key: com.google.android.calendar_in_2025-09-08 - 2025-09-09_2025-09-01 - 2025-09-02\n",
            "Available cache keys: ['com.google.android.calendar_in_2025-09-08 - 2025-09-09_2025-09-01 - 2025-09-02']\n",
            "127.0.0.1 - - [16/Sep/2025 08:15:45] \"POST /view-cache HTTP/1.1\" 200 -\n",
            "Analyzing 164 present and 153 previous reviews.\n",
            "Processing 164 reviews...\n",
            "--- LOADING SENTIMENT CLASSIFIER (OPTIMIZED) ---\n",
            "Using device: cpu\n",
            "config.json: 100% 929/929 [00:00<00:00, 4.83MB/s]\n",
            "vocab.json: 899kB [00:00, 1.92MB/s]\n",
            "merges.txt: 456kB [00:00, 1.12MB/s] \n",
            "special_tokens_map.json: 100% 239/239 [00:00<00:00, 1.16MB/s]\n",
            "2025-09-16 08:16:14.684234: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1758010574.732855    9412 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1758010574.747066    9412 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1758010574.788567    9412 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1758010574.788634    9412 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1758010574.788643    9412 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1758010574.788651    9412 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-09-16 08:16:14.801384: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "pytorch_model.bin: 100% 501M/501M [00:12<00:00, 39.6MB/s]\n",
            "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "âœ… Classifier model loaded and optimized.\n",
            "Processing batch 1/11\n",
            "model.safetensors: 100% 501M/501M [00:09<00:00, 51.0MB/s]\n",
            "Processing batch 2/11\n",
            "Processing batch 3/11\n",
            "Processing batch 4/11\n",
            "Processing batch 5/11\n",
            "Processing batch 6/11\n",
            "Processing batch 7/11\n",
            "Processing batch 8/11\n",
            "Processing batch 9/11\n",
            "Processing batch 10/11\n",
            "Processing batch 11/11\n",
            "ðŸš€ Making Gemini API call #1...\n",
            "Present analysis completed in 86.47s\n",
            "Processing 153 reviews...\n",
            "Processing batch 1/10\n",
            "Processing batch 2/10\n",
            "Processing batch 3/10\n",
            "Processing batch 4/10\n",
            "Processing batch 5/10\n",
            "Processing batch 6/10\n",
            "Processing batch 7/10\n",
            "Processing batch 8/10\n",
            "Processing batch 9/10\n",
            "Processing batch 10/10\n",
            "Previous analysis completed in 120.03s\n",
            "ðŸš€ Making Gemini API call #2...\n",
            "Total analysis completed in 122.95s\n",
            "127.0.0.1 - - [16/Sep/2025 08:18:06] \"POST /analyze HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [16/Sep/2025 08:18:06] \"POST /analyze HTTP/1.1\" 200 -\n"
          ]
        }
      ]
    }
  ]
}